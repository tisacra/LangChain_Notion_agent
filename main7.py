# === LangChain + Notion ãƒ–ãƒ­ãƒƒã‚¯è¿½è¨˜ç‰ˆ (ConversationBufferMemory + VectorStoreçµ±åˆ) ===
'''
graph TD
    A[ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›] --> B{ä¿å­˜æŒ‡ç¤ºã‚ã‚Šã‹}
    B -->|ã‚ã‚Š| C[ConversationBufferMemory ã‹ã‚‰å±¥æ­´å–å¾—]
    C --> D[å±¥æ­´ã‚’è¦ç´„ (LLM)]
    D --> E[Notion å›ºå®šãƒšãƒ¼ã‚¸ã«ãƒ–ãƒ­ãƒƒã‚¯è¿½è¨˜]
    D --> F[è¦ç´„å†…å®¹ã‚’ VectorStore ã«è¿½åŠ ]
    B -->|ãªã—| G[VectorStore ã§é¡ä¼¼å±¥æ­´æ¤œç´¢]
    G --> H[ConversationBufferMemory ã®å±¥æ­´ã¨æ¤œç´¢çµæœã‚’ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«æŒ¿å…¥]
    H --> I[LLM å¿œç­”ç”Ÿæˆ]
    I --> J[ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«å›ç­”è¡¨ç¤º]
    A --> K[ConversationBufferMemory ã«ç™ºè©±è¿½åŠ ]
    I --> K
'''

from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain.vectorstores import FAISS
from langchain.memory import ConversationBufferMemory
import os
from dotenv import load_dotenv
import pickle
import shutil

import subsystem.Notion_func as Notion_func

SUMMARIZE_LOCAL = False

# === å‹•çš„è¦ç´„è¨­å®š ===
from langchain_community.chat_models import ChatOllama

# è¦ç´„å°‚ç”¨ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
local_summarizer = ChatOllama(model="mistral")

# è¦ç´„æ™‚ã®ã¿åˆ‡ã‚Šæ›¿ãˆ
def local_summarize_memory():
    global summary_memory
    current_history = "".join([msg.content for msg in memory.load_memory_variables({})["history"]])
    prompt = current_history + "\n" + """
    ã“ã®è­°è«–å†…å®¹ã‚’Notionã«ä¿å­˜ã™ã‚‹ã®ã«é©ã—ãŸå½¢ã§è¦ç´„ã—ã¦ãã ã•ã„ã€‚
    ç‰¹ã«ã€è³ªç–‘å¿œç­”ã‚’é‡è¦–ã—ã¦ã€[è³ªå•]â†’[å›ç­”]ã®å½¢å¼ã§ç¤ºã™ã‚ˆã†ã«ã—ã¦ãã ã•ã„ã€‚
    """
    print(f"ğŸ“ è¦ç´„ã—ã¾ã™: {prompt}")
    summary = local_summarizer.invoke(prompt).content
    summary_memory += f"\n{summary}"
    print(f"ğŸ“ è¦ç´„è¿½åŠ  (ãƒ­ãƒ¼ã‚«ãƒ«): {summary}")
    memory.clear()


SUMMARY_INTERVAL = 3  # 3ã‚¿ãƒ¼ãƒ³ã”ã¨ã«è¦ç´„
summary_memory = ""  # è¦ç´„è“„ç©ç”¨

# === ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿ ===
load_dotenv()

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
OPENAI_ORGANIZATION_ID = os.getenv("OPENAI_ORGANIZATION_ID")
PAGE_ID = os.getenv("PAGE_ID")
DATABASE_ID = os.getenv("DATABASE_ID")
MEMORY_PATH = "memory.pkl"
VECTORSTORE_PATH = "vectorstore_index"

if not PAGE_ID:
    raise ValueError("PAGE_ID is not set in .env file")

# === LLMã®åˆæœŸåŒ– ===
llm = ChatOpenAI(
    api_key=OPENAI_API_KEY,
    organization=OPENAI_ORGANIZATION_ID,
    model_name="gpt-3.5-turbo"
)

embeddings = OpenAIEmbeddings()

# === Memoryã®åˆæœŸåŒ– ===
def load_memory():
    if os.path.exists(MEMORY_PATH):
        with open(MEMORY_PATH, "rb") as f:
            return pickle.load(f)
    return ConversationBufferMemory(return_messages=True)

def save_memory(memory):
    with open(MEMORY_PATH, "wb") as f:
        pickle.dump(memory, f)

def refresh_memory():
    """ä¼šè©±å±¥æ­´ã‚’ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥ã™ã‚‹"""
    global memory
    memory = ConversationBufferMemory(return_messages=True)
    if os.path.exists(MEMORY_PATH):
        os.remove(MEMORY_PATH)
    print("ğŸ”„ ä¼šè©±å±¥æ­´ã‚’ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥ã—ã¾ã—ãŸ")

memory = load_memory()

# === VectorStoreã®åˆæœŸåŒ– ===
def load_vectorstore():
    """VectorStoreã‚’ãƒ­ãƒ¼ãƒ‰ã€ãªã‘ã‚Œã°æ–°è¦ä½œæˆ"""
    if os.path.exists(VECTORSTORE_PATH):
        return FAISS.load_local(VECTORSTORE_PATH, embeddings, allow_dangerous_deserialization=True)
    
    # åˆæœŸåŒ–æ™‚ã¯æœ€ä½1ã¤ã®ãƒ†ã‚­ã‚¹ãƒˆãŒå¿…è¦
    vectorstore = FAISS.from_texts(
        ["åˆæœŸåŒ–ç”¨ã®ãƒ€ãƒŸãƒ¼ãƒ†ã‚­ã‚¹ãƒˆã§ã™ã€‚ã“ã®ãƒ†ã‚­ã‚¹ãƒˆã¯æ¤œç´¢ã«ã¯ä½¿ç”¨ã•ã‚Œã¾ã›ã‚“ã€‚"],
        embeddings
    )
    vectorstore.save_local(VECTORSTORE_PATH)
    return vectorstore

def save_vectorstore(store):
    """VectorStoreã‚’ä¿å­˜"""
    store.save_local(VECTORSTORE_PATH)

def refresh_vectorstore():
    """VectorStoreã‚’ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥ã™ã‚‹"""
    global vectorstore
    # åˆæœŸåŒ–æ™‚ã¯æœ€ä½1ã¤ã®ãƒ†ã‚­ã‚¹ãƒˆãŒå¿…è¦
    vectorstore = FAISS.from_texts(
        ["åˆæœŸåŒ–ç”¨ã®ãƒ€ãƒŸãƒ¼ãƒ†ã‚­ã‚¹ãƒˆã§ã™ã€‚ã“ã®ãƒ†ã‚­ã‚¹ãƒˆã¯æ¤œç´¢ã«ã¯ä½¿ç”¨ã•ã‚Œã¾ã›ã‚“ã€‚"],
        embeddings
    )
    if os.path.exists(VECTORSTORE_PATH):
        try:
            shutil.rmtree(VECTORSTORE_PATH)
        except Exception as e:
            print(f"âš ï¸ VectorStoreã®å‰Šé™¤ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            return
    print("ğŸ”„ VectorStoreã‚’ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥ã—ã¾ã—ãŸ")

def refresh_all():
    """ä¼šè©±å±¥æ­´ã¨VectorStoreä¸¡æ–¹ã‚’ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥ã™ã‚‹"""
    refresh_memory()
    refresh_vectorstore()
    print("âœ¨ å…¨ã¦ã®ãƒ‡ãƒ¼ã‚¿ã‚’ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥ã—ã¾ã—ãŸ")

vectorstore = load_vectorstore()



# === ä¿å­˜æŒ‡ç¤ºåˆ¤å®š ===
def is_valid_save_command(user_input):
    if "ä¿å­˜" not in user_input:
        return False

    prompt = f"""
    ä»¥ä¸‹ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ç™ºè©±ã¯ã€AIã¨ã®è­°è«–å†…å®¹ã‚’Notionã«ä¿å­˜ã™ã‚‹ã‚ˆã†ã«ä¾é ¼ã—ã¦ã„ã‚‹æ„å›³ãŒã‚ã‚Šã¾ã™ã‹ï¼Ÿ
    ã€Œã¯ã„ã€ã¾ãŸã¯ã€Œã„ã„ãˆã€ã§ç­”ãˆã¦ãã ã•ã„ã€‚

    ç™ºè©±: "{user_input}"
    """
    decision = llm.invoke(prompt).content
    #print(f"åˆ¤æ–­çµæœ: {decision}")
    return "ã¯ã„" in decision

# === è¦ç´„é–¢æ•° ===
def summarize_memory():
    global summary_memory
    current_history = "".join([msg.content for msg in memory.load_memory_variables({})["history"]])
    prompt = f"""
    ä»¥ä¸‹ã®è­°è«–å±¥æ­´ã‚’ç°¡æ½”ã«è¦ç´„ã—ã¦ãã ã•ã„ã€‚
    ç‰¹ã«ã€è³ªç–‘å¿œç­”ã‚’é‡è¦–ã—ã¦ã€[è³ªå•]â†’[å›ç­”]ã®å½¢å¼ã§ç¤ºã™ã‚ˆã†ã«ã—ã¦ãã ã•ã„ã€‚

    {current_history}
    """
    summary = llm.invoke(prompt).content
    summary_memory += f"\n{summary}"
    print(f"ğŸ“ è¦ç´„è¿½åŠ : {summary}")
    memory.clear()

# === å®Ÿè¡Œä¾‹ ===
if __name__ == "__main__":
    turn_counter = 0
    try:
        while True:
            user_input = input("> ")
            if user_input.lower() in ["exit", "quit"]:
                break
            elif user_input.lower() in ["refresh", "clear"]:
                refresh_all()
                continue
            elif user_input.lower() == "refresh memory":
                refresh_memory()
                continue
            elif user_input.lower() == "refresh vectorstore":
                refresh_vectorstore()
                continue

            if is_valid_save_command(user_input):
                print("ğŸ’¾ ä¿å­˜æŒ‡ç¤ºãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸã€‚æŒ‡å®šãƒšãƒ¼ã‚¸ã«è¿½è¨˜ã—ã¾ã™ã€‚")
                summary_prompt = """
                ã“ã‚Œã¾ã§ã®è­°è«–å†…å®¹ã‚’Notionã«ä¿å­˜ã™ã‚‹ã®ã«é©ã—ãŸå½¢ã§è¦ç´„ã—ã¦ãã ã•ã„ã€‚
                ç‰¹ã«ã€è³ªç–‘å¿œç­”ã‚’é‡è¦–ã—ã¦ã€[è³ªå•]â†’[å›ç­”]ã®å½¢å¼ã§ç¤ºã™ã‚ˆã†ã«ã—ã¦ãã ã•ã„ã€‚
                """
                history = memory.load_memory_variables({})["history"]
                # ãƒªã‚¹ãƒˆã‚’æ–‡å­—åˆ—ã«å¤‰æ›ã—ã¦ã‹ã‚‰é€£çµ
                messages = summary_memory + "\n".join([msg.content for msg in history]) + f"\n{summary_prompt}"
                print(f"è¦ç´„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {messages}")
                summary = llm.invoke(messages).content

                # Notionä¿å­˜
                Notion_func.append_to_page(PAGE_ID, summary)

                # VectorStoreç™»éŒ²
                vectorstore.add_texts([summary])
                print("ğŸ”„ VectorStoreã«è¦ç´„ã‚’è¿½åŠ ã—ã¾ã—ãŸã€‚")
                
                try:
                    save_vectorstore(vectorstore)
                except Exception as e:
                    print(f"âš ï¸ VectorStoreã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

                #memory.chat_memory.add_ai_message(summary)
                turn_counter += 1

            else:
                memory.chat_memory.add_user_message(user_input)
                # é–¢é€£å±¥æ­´æ¤œç´¢ (çœç•¥å¯)
                user_query = user_input
                docs = vectorstore.similarity_search(user_query, k=2)
                retrieved = "\n".join([d.page_content for d in docs])

                # LLMå¿œç­”
                history = summary_memory + "\n".join([msg.content for msg in memory.load_memory_variables({})["history"]])
                prompt = history + f"\nãƒ¦ãƒ¼ã‚¶ãƒ¼: {user_input}"
                result = llm.invoke(prompt).content
                print(result)
                memory.chat_memory.add_ai_message(result)
                turn_counter += 1
            
            # å‹•çš„è¦ç´„
            if turn_counter % SUMMARY_INTERVAL == 0:
                if SUMMARIZE_LOCAL:
                    local_summarize_memory()
                else:
                    summarize_memory()
                print(f"ğŸ”„ å‹•çš„è¦ç´„: {summary_memory}")

    finally:
        save_memory(memory)
        print("âœ… ä¼šè©±å±¥æ­´ã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚")
